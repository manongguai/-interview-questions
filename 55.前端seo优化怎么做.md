1. tdk : title, meta description, meta keywords (keywords 百度和谷歌几乎放弃，目前必应还支持)
2. html 标签语义化 h strong em ul ol li nav aside header article section footer
3. 搜索引擎收录 百度站长，谷歌网站管理员等
4. sitemap.xml 网站地图 它是一个网站的全部 URL 列表
5. robots.txt 蜘蛛在访问一个网站时，会首先会检查该网站的根域下是否有一个叫做 robots.txt 的纯文本文件，这个文件用于指定 spider 在您网站上的抓取范围。

如果你有哪些页面不想被蜘蛛访问，则可以通过 robots 文件告诉蜘蛛不想被搜索引擎收录的部分或者指定搜索引擎只收录特定的部分。

robots 文件内容语法：
此文件主要由两种键值对组成：

User-agent: 该项的值用于描述搜索引擎蜘蛛的名字。如果该项的值设为\*，则该协议对任何机器人均有效。
Disallow: 该项的值用于描述不希望被访问到的一个 URL，一个目录或者整个网站。以 Disallow 开头的 URL 均不会被搜索引擎蜘蛛访问到。任何一条 Disallow 记录为空，说明该网站的所有部分都允许被访问。

6. https
7. 伪静态
